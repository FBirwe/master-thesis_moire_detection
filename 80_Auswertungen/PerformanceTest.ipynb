{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aacbbba8-0c0a-4735-9fb2-b6c3ff648159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../30_data_tools/')\n",
    "sys.path.append('../60_gebastel/Model/')\n",
    "\n",
    "from calc_model_results import load_model\n",
    "from pytorch_model_tools import get_radius_map, img_to_fft\n",
    "from helper import load_dotenv\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from random import choices, choice\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe7c1bd-cb04-4087-a937-d0ffade2ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70593041-ed39-4ee4-94b9-cf7dea57b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_map = get_radius_map()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img_to_fft(img, radius_map)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6285ae5b-a9fb-418a-bad8-adc5cac1235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = load_model('2024-05-13_Resnet50_004')\n",
    "model_mobilenet = load_model('2024-05-12_MobileNetV3_003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11191cc3-4f3b-474e-830b-5cdfe63b5ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.eval()\n",
    "model_mobilenet.eval()\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959f854d-b03c-4ff9-92e5-8b9f9c48cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = list((dotenv['TILE_DATASET_DIR'] / 'train' / 'moire').glob('./*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346a4d5c-0b96-4724-9b5e-f9df17982143",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = choices( tiles, k=5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3529b1-e239-4e7f-b9c8-c46e40da2f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbc93e39ef1435aa9d4da5b0d09c1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for tile_path in tqdm(sample):\n",
    "    tile_img = Image.open(tile_path)\n",
    "    tile_tensor = transform(tile_img).reshape((1,3,224,224))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model_resnet(tile_tensor)\n",
    "\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c46fc0-3dfe-48a3-ac3b-8ac76b0ce753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ResNet: ', 398.9852547645569)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ResNet: \", (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ce8c72-1207-43a5-88ae-fd259e6b1a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebde15266e9f48559a34a0ba4d031c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for tile_path in tqdm(sample):\n",
    "    tile_img = Image.open(tile_path)\n",
    "    tile_tensor = transform(tile_img).reshape((1,3,224,224))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model_mobilenet(tile_tensor)\n",
    "\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc25a64c-7d56-4a17-a584-8e7c8810a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MobileNet: ', 1348.4395728111267)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MobileNet: \", (end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
