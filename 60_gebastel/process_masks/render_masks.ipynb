{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576ccec6-3b9f-423a-9167-3a61d0948497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../30_data_tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175496fe-e026-4b98-b6f1-3b34d5980246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d052c0d5-8650-4dbc-bcb2-a49f3f576193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_functions import get_config, load_mask_img, is_below_max_size, is_above_min_size, is_text_mask, filter_intersected_masks, save_masks\n",
    "from helper import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ee2338-025e-4a4e-84d1-db1388d7f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1edca00-fe57-456f-af3d-a8bf73ebc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "config['target_variant'] = 'halftone600dpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ea75ac-9a25-4b66-b1c9-fd80b932fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b448830-6cbd-40ad-8c05-c22965858c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(dotenv['DB_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca8d55d-150b-4e79-9589-71039e2c17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_pages = pd.read_sql(\n",
    "    f'''\n",
    "        SELECT cf.* FROM (\n",
    "        \tSELECT * FROM related_file\n",
    "        \tWHERE variant_name = '{ config[\"target_variant\"] }' AND \"type\" = '4c'\n",
    "        ) cf\n",
    "        LEFT JOIN (\n",
    "        \tSELECT job, pdf_filename, 1 AS has_mask FROM related_file \n",
    "        \tWHERE variant_name = '{ config[\"target_variant\"] }' AND \"type\" = 'masks'\n",
    "        ) mf ON cf.job=mf.job AND cf.pdf_filename=mf.pdf_filename \n",
    "        WHERE mf.has_mask IS NULL\n",
    "    ''',\n",
    "    con\n",
    ").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29d5014-a1d8-4567-a9e7-aacdf3605825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b82ba9-c34d-4350-9bb4-b258c05d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f268c6-8125-4c51-87a6-d68cbf29ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[\"vit_h\"](checkpoint=dotenv['MODEL_DIR'] / \"sam_vit_h_4b8939.pth\")\n",
    "#sam.to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f11c72-423d-4bb9-b7d0-41a76199a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 1083/1083 [00:00<00:00, 24852.59it/s]\n"
     ]
    }
   ],
   "source": [
    "relevant_indexes = []\n",
    "\n",
    "for i in tqdm(range(remaining_pages.shape[0])):\n",
    "    row = remaining_pages.iloc[i]\n",
    "    img_path = dotenv['DATA_DIR'] / row['job'] / row['variant_name'] / row['filename']\n",
    "    \n",
    "    mask_path = img_path.parent / f'{ img_path.name.strip( \".\" + row[\"type\"] + img_path.suffix ) }.masks.pkl'\n",
    "    mask_path_300dpi = dotenv['DATA_DIR'] / row['job'] / 'halftone300dpi' / mask_path.name\n",
    "\n",
    "    if mask_path.exists() == False and mask_path_300dpi.exists() == False:\n",
    "        relevant_indexes.append(row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a7bdf44-c944-4f82-8ba2-a0427f7961c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'956/1083; 127 verbleibend'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{remaining_pages.shape[0] - len(relevant_indexes)}/{remaining_pages.shape[0]}; { len(relevant_indexes) } verbleibend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f858f4c-bab0-44bb-bddf-fed09d8357a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae61dc-45e6-471c-b65f-2fdcc4183af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_rows = []\n",
    "\n",
    "for idx in tqdm(relevant_indexes):\n",
    "    row = remaining_pages.loc[idx]\n",
    "    img_path = dotenv['DATA_DIR'] / row['job'] / row['variant_name'] / row['filename']\n",
    "    \n",
    "    mask_path = img_path.parent / f'{ img_path.name.strip( \".\" + row[\"type\"] + img_path.suffix ) }.masks.pkl'\n",
    "    mask_path_300dpi = dotenv['DATA_DIR'] / row['job'] / 'halftone300dpi' / mask_path.name\n",
    "\n",
    "    if mask_path_300dpi.exists() == False:\n",
    "        times = []\n",
    "        img = Image.open(img_path)\n",
    "        orig_size = img.size\n",
    "        img = img.resize((\n",
    "            int( round(img.size[0] * config['MASK_IMG_SCALE_FACTOR']) ),\n",
    "            int( round(img.size[1] * config['MASK_IMG_SCALE_FACTOR']) )\n",
    "        ))\n",
    "        \n",
    "        start = time()\n",
    "        times.append((\"start\",time()))\n",
    "        masks = mask_generator.generate( np.array(img.convert(\"RGB\")) )\n",
    "        #print( f\"mask generation took: { ( time() - start ) }\")\n",
    "        times.append((\"masks generated\",time()))\n",
    "        \n",
    "        for m in masks:\n",
    "            factor_x = orig_size[0] / m['segmentation'].shape[1]\n",
    "            factor_y = orig_size[1] / m['segmentation'].shape[0]\n",
    "            \n",
    "            m['segmentation'] = m['segmentation'][\n",
    "                int(m['bbox'][1]):int(m['bbox'][1]+m['bbox'][3]+1),\n",
    "                int(m['bbox'][0]):int(m['bbox'][0]+m['bbox'][2]+1)\n",
    "            ]\n",
    "            m['bbox'] = [\n",
    "                int(round(m['bbox'][0] * factor_x)),\n",
    "                int(round(m['bbox'][1] * factor_y)),\n",
    "                int(round(m['bbox'][2] * factor_x)),\n",
    "                int(round(m['bbox'][3] * factor_y))\n",
    "            ]\n",
    "            m['point_coords'] = [[\n",
    "                int(round(m['point_coords'][0][0] * factor_x)),\n",
    "                int(round(m['point_coords'][0][1] * factor_y)),\n",
    "            ]]\n",
    "    \n",
    "            m['crop_box'] = [\n",
    "                int(round(m['crop_box'][0] * factor_x)),\n",
    "                int(round(m['crop_box'][1] * factor_y)),\n",
    "                int(round(m['crop_box'][2] * factor_x)),\n",
    "                int(round(m['crop_box'][3] * factor_y))\n",
    "            ]\n",
    "\n",
    "        masks = [m for m in masks if m['area'] < (img.size[0] * img.size[1] * 0.25)]\n",
    "        times.append((\"area filtered\",time()))\n",
    "        \n",
    "        masks_out = []\n",
    "\n",
    "        for m in masks:\n",
    "            mask_out = {\n",
    "                'mask' : m['segmentation'],\n",
    "                'bbox' : m['bbox'],\n",
    "                'predicted_iou' : m['predicted_iou'],\n",
    "                'stability_score' : m['stability_score'],\n",
    "                'img_size' : orig_size\n",
    "            }\n",
    "            mask_out['mask'] = load_mask_img(mask_out)\n",
    "            masks_out.append(mask_out)\n",
    "\n",
    "        \n",
    "        masks_out = [m for m in masks_out if is_below_max_size(m)]\n",
    "        # filter by size\n",
    "        masks_out = [m for m in masks_out if is_above_min_size(m)]\n",
    "        times.append((\"size filtered\",time()))\n",
    "        # filter by text box\n",
    "        masks_out = [m for m in masks_out if is_text_mask( img, m ) == False]\n",
    "        times.append((\"text mask\",time()))\n",
    "        # filter duplicates\n",
    "        masks_out = filter_intersected_masks( masks_out )\n",
    "        times.append((\"intersected\",time()))\n",
    "        time_rows.append(times)\n",
    "        \n",
    "        save_masks( masks_out, mask_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f966d-4ca2-4f2e-893b-3e6cd197b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "for i in range(len(time_rows)):\n",
    "    times += [(i+1, t[0], t[1] - time_rows[i][0][1]) for t in time_rows[i]]\n",
    "\n",
    "time_df = pd.DataFrame(\n",
    "    times,\n",
    "    columns=['run','step','duration']\n",
    ").set_index(['run','step'])\n",
    "\n",
    "time_df = time_df.unstack('step')\n",
    "time_df.columns = [c[1] for c in time_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0081d4-fe66-4d8d-a1b6-4c6a3bf6ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384f7cd-cb0e-4dfa-8b6c-4b88c9606a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(time_df.intersected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dadd7f-e4cc-4777-9f22-b6bc74f19137",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.intersected.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d292a-8ce8-42d1-a35a-63cfd44457e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.intersected - time_df['text mask']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
