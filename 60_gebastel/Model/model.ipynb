{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01ffdc-861d-44e6-8aac-2eda523b9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822d1b7-6ee5-495d-ac0c-397e660f79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import nasnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85808460-7582-4252-81b0-01d5830307f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import re\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b2bbe-54fe-49ff-867b-6257cc839002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72df2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset import get_available_moires, get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f80cf-6256-42b0-93e8-3b37e44ff63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0378db-b732-409f-a15c-c27123e64750",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (150,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb80d4-eb7f-42f0-a77f-72f0942f490b",
   "metadata": {},
   "source": [
    "# Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fb6c5c-b045-4084-b225-f0ea4fa3c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_available_moires()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668e5aae-0617-4b91-a856-d7f69a480bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▋           | 196/271 [12:48<00:58,  1.27it/s]/Users/frederic.birwe/Library/Python/3.10/lib/python/site-packages/PIL/Image.py:3182: DecompressionBombWarning: Image size (127715826 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 271/271 [14:36<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "data, labels = get_train_data( df, IMG_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9003ee8-6e94-487c-aed9-fbd47e4b08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb87f9-6d64-4b88-b807-a97cba78a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    vertical_flip=True,\n",
    "    #preprocessing_function=randomly_reorder_channels,\n",
    "    validation_split=0.2,\n",
    "    #channel_shift_range=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0371c43-5ba4-4b91-9bfc-5466b6005fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced38f15-7f0d-4318-926f-32c239cdf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b3018-ac93-415c-bee0-9a95166f59ef",
   "metadata": {},
   "source": [
    "# Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4471a9-4668-4f12-97a6-2336b9254f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db8268-04be-44cc-9971-e45f06459f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2712c0-8584-4a44-9699-53c500eec325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481048dc-1e59-4a71-91fe-1915af17e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
