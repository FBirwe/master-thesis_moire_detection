{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f9642-6dfd-4916-b7be-8538855717e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../30_data_tools/')\n",
    "sys.path.append('../process_masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ee079-1e2d-4a21-aa25-92087893f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "from helper import load_dotenv\n",
    "from get_labelstudio_data import get_moires_of_project\n",
    "from mask_functions import load_masks, get_whole_mask\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from load_dataset import get_available_moires, get_train_data, get_moire_path, get_non_moire_path, get_results_of_project\n",
    "from get_labelstudio_data import get_results_of_project\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ae7c7-06cc-4646-af7a-786d74ef27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_interaction import get_generic_image_filepath, get_related_filepath, open_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7d609-0aa2-4a90-b426-d3fa35bcec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690df52-d165-4e91-abd3-06a4c3b4dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (\n",
    "    224,\n",
    "    224\n",
    ")\n",
    "RESOLUTIONS = [300,200,150]\n",
    "MIN_MASK_PARTIAL = 0.25\n",
    "MIN_TILE_PARTIAL = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37a962-ea79-4d61-a06a-3349f088830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720276b-1b4b-48f0-950b-463aee584a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = dotenv['TILE_DATASET_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b882240-1fcc-4524-83f6-83fa1d89f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect( dotenv['DB_PATH'] ) as con:\n",
    "    data = pd.merge(\n",
    "        pd.read_sql(\n",
    "            '''\n",
    "                SELECT m.* FROM mask m\n",
    "                LEFT JOIN generic_image gi \n",
    "                ON\n",
    "                \tm.job=gi.job AND\n",
    "                \tm.pdf_filename=gi.pdf_filename AND\n",
    "                \tm.\"type\"=gi.\"type\" AND\n",
    "                \tm.variant_name=gi.variant_name AND\n",
    "                \tm.\"method\"=gi.\"method\" AND\n",
    "                \tm.idx=gi.idx \n",
    "                WHERE\n",
    "                \tgi.job='24-03-05-01_randomTrainPages'\n",
    "            ''',\n",
    "            con\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            [(r['id'],r['labels'][0],r['updated_at']) for r in get_results_of_project(2) if 'id' in r],\n",
    "            columns=['mask_id','label','updated_at']\n",
    "        ),\n",
    "        on='mask_id',\n",
    "        how='left'\n",
    "    )\n",
    "    data.label.fillna('undefined', inplace=True)\n",
    "    data = data.loc[\n",
    "        data.label == 'checked_moire'\n",
    "    ]\n",
    "\n",
    "    already_processed_mask_ids = list(set([\n",
    "        re.match(r'(.+)_\\d{3}.\\d+', e.name.replace(e.suffix,'')).groups()[0]\n",
    "         for e in DATASET_DIR.glob('./**/*.jpg')\n",
    "    ]))\n",
    "    \n",
    "    data = data.loc[\n",
    "        data.mask_id.isin(already_processed_mask_ids) == False\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0b50b-294e-414f-9e75-e4117327bdd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a01e9a-3bd5-4252-ae8e-2191c7ce14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_img_by_dpi( img, source_dpi, target_dpi ):\n",
    "    if target_dpi != source_dpi:\n",
    "        img = img.resize((\n",
    "            round(img.size[0] * (target_dpi / source_dpi)),\n",
    "            round(img.size[1] * (target_dpi / source_dpi))\n",
    "        ))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def rescale_mask_by_target_size( mask, img_size ):\n",
    "    whole_mask = (get_whole_mask( mask ) * 255).astype('uint8')\n",
    "    mask = cv2.resize(\n",
    "        whole_mask,\n",
    "        img_size\n",
    "    )\n",
    "    mask = (mask / 255).astype('bool')\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def rescale_bounding_box_by_rescale_factor( bounding_box, rescale_factor ):\n",
    "    return [\n",
    "        int(round(bounding_box[0] * rescale_factor[0])),\n",
    "        int(round(bounding_box[1] * rescale_factor[1])),\n",
    "        int(round(bounding_box[2] * rescale_factor[0])),\n",
    "        int(round(bounding_box[3] * rescale_factor[1]))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee65cb-abf8-42de-860a-c00be8a9540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_pair( row, dotenv ):   \n",
    "    non_moire_path = get_related_filepath( row.job, 'ps2400dpi150lpi', f'{ row.pdf_filename }.4c_{ dotenv[\"LOFI_DPI\"] }.jpg' )\n",
    "    moire_path = get_generic_image_filepath( row.pdf_filename, row.job, row.method, row.idx, variant=f'4c_{ dotenv[\"LOFI_DPI\"] }'  )\n",
    "    moire_img = open_img( moire_path )\n",
    "    non_moire_img = open_img( non_moire_path )\n",
    "\n",
    "    return non_moire_img, moire_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6995bad-dc79-400c-91d5-174a00cce997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_img_to_tiles( img, relevant_box, mask=None, is_polygon_box=False ):\n",
    "    # convolve over image\n",
    "    out = []\n",
    "    conv_size = IMG_SIZE\n",
    "    step_horizontal = int(round(conv_size[0] / 2))\n",
    "    step_vertical = int(round(conv_size[1] / 2))\n",
    "    tile_partial = 0\n",
    "    \n",
    "    for left in range(0, img.shape[1] - step_horizontal, step_horizontal):\n",
    "        for top in range(0, img.shape[0] - step_vertical, step_vertical):\n",
    "            \n",
    "            if left + conv_size[0] > img.shape[1]:\n",
    "                left = img.shape[1] - conv_size[0]\n",
    "\n",
    "            if top + conv_size[1] > img.shape[0]:\n",
    "                top = img.shape[0] - conv_size[1]\n",
    "\n",
    "            if (mask is None) == False:\n",
    "                mask_partial = mask[\n",
    "                    top:top+conv_size[1],\n",
    "                    left:left+conv_size[0]\n",
    "                ].mean()   \n",
    "            elif is_polygon_box:\n",
    "                p_label = Polygon(relevant_box)\n",
    "                p_tile = Polygon([\n",
    "                    (left,top),\n",
    "                    (left + step_horizontal,top),\n",
    "                    (left + step_horizontal,top + step_vertical),\n",
    "                    (left,top + step_vertical)\n",
    "                ])\n",
    "\n",
    "                mask_partial = p_label.intersection(p_tile).area / p_tile.area\n",
    "                tile_partial = p_label.intersection(p_tile).area / p_label.area\n",
    "            else:\n",
    "                # ist keine Maske vorhanden wird die Intersection\n",
    "                # mit der Moirebox verwendet\n",
    "                intersection_box = [\n",
    "                    max([relevant_box[0], left]),\n",
    "                    max([relevant_box[1], top]),\n",
    "                    min([relevant_box[0] + relevant_box[2], left+conv_size[0]]),\n",
    "                    min([relevant_box[1] + relevant_box[3], top+conv_size[1]])\n",
    "                ]\n",
    "        \n",
    "                if intersection_box[0] <= intersection_box[2] and intersection_box[1] <= intersection_box[3]:\n",
    "                    mask_partial = ((intersection_box[2] - intersection_box[0]) * (intersection_box[3] - intersection_box[1]))  / (conv_size[0] * conv_size[1])      \n",
    "                else:\n",
    "                    mask_partial = 0\n",
    "\n",
    "            if mask_partial > MIN_MASK_PARTIAL or tile_partial > MIN_TILE_PARTIAL:\n",
    "                out.append(\n",
    "                    img[\n",
    "                        top:top+conv_size[1],\n",
    "                        left:left+conv_size[0]\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5ad61-5ac3-4dba-be77-4b89a541eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample( row, dotenv ):\n",
    "    bbox = [int(val) for val in row.bbox.split(';')]\n",
    "    masks = [m for m in load_masks( get_related_filepath( row.job, f'halftone{dotenv[\"LOFI_DPI\"]}dpi', f'{ row.pdf_filename }.masks.pkl' ) ) if m['bbox'] == bbox]\n",
    "    orig_non_moire_img, orig_moire_img = get_img_pair( row, dotenv )\n",
    "    original_size = orig_non_moire_img.size\n",
    "    \n",
    "    if len(masks) > 0:\n",
    "        whole_mask = (get_whole_mask( masks[0] ) * 255).astype('uint8')\n",
    "        use_mask=True\n",
    "    else:\n",
    "        use_mask=False\n",
    "    \n",
    "    moire_samples = []\n",
    "    non_moire_samples = []\n",
    "\n",
    "    for resolution in RESOLUTIONS:\n",
    "        non_moire_img = rescale_img_by_dpi(\n",
    "            orig_non_moire_img,\n",
    "            dotenv[\"LOFI_DPI\"],\n",
    "            resolution\n",
    "        )\n",
    "        non_moire_img = 1 - np.array(non_moire_img)[:,:,3] / 255\n",
    "        \n",
    "        moire_img = rescale_img_by_dpi(\n",
    "            orig_moire_img,\n",
    "            dotenv[\"LOFI_DPI\"],\n",
    "            resolution\n",
    "        )\n",
    "        moire_img = 1 - np.array(moire_img)[:,:,3] / 255\n",
    "\n",
    "        rescale_factor = [\n",
    "            moire_img.shape[1] / original_size[0],\n",
    "            moire_img.shape[0] / original_size[1]\n",
    "        ]\n",
    "        \n",
    "        mask_box = rescale_bounding_box_by_rescale_factor(\n",
    "            bbox,\n",
    "            rescale_factor\n",
    "        )\n",
    "\n",
    "        if use_mask:\n",
    "            mask = (cv2.resize(\n",
    "                whole_mask,\n",
    "                (non_moire_img.shape[1], non_moire_img.shape[0])\n",
    "            ) / 255).astype('bool')\n",
    "        else:\n",
    "            mask = None\n",
    "        \n",
    "        moire_samples.append((resolution, cut_img_to_tiles( moire_img, mask_box, mask=mask)))\n",
    "        non_moire_samples.append((resolution, cut_img_to_tiles( non_moire_img, mask_box, mask=mask)))\n",
    "\n",
    "    # out berechnen\n",
    "    out = []\n",
    "\n",
    "    for i in range(len(moire_samples)):\n",
    "        resolution,moire_tiles = moire_samples[i]\n",
    "        _,non_moire_tiles = non_moire_samples[i]\n",
    "\n",
    "        out += [(f'{ row.mask_id }_{ resolution }', non_moire_tiles[j], moire_tiles[j]) for j in range(len(moire_tiles))]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78177fa1-78d3-475a-bd15-c29edf6eb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_val_split( data, labels, test_size=.2, val_size=.1 ):\n",
    "    idx_list = [i for i in range(len(data))]\n",
    "    random.shuffle(idx_list)\n",
    "    test_limiter = round(len(idx_list) * test_size)\n",
    "    val_limiter = test_limiter + round(len(idx_list) * val_size)\n",
    "\n",
    "    train_data = [data[idx] for idx in idx_list[val_limiter:]]\n",
    "    train_labels = [labels[idx] for idx in idx_list[val_limiter:]]\n",
    "\n",
    "    test_data = [data[idx] for idx in idx_list[:test_limiter]]\n",
    "    test_labels = [labels[idx] for idx in idx_list[:test_limiter]]\n",
    "\n",
    "    val_data = [data[idx] for idx in idx_list[test_limiter:val_limiter]]\n",
    "    val_labels = [labels[idx] for idx in idx_list[test_limiter:val_limiter]]\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, val_data, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c66b74-ea2e-4434-9693-522e6cd86c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tiles( data, set_name ):\n",
    "    set_dir = DATASET_DIR / set_name\n",
    "    if set_dir.exists() == False:\n",
    "        set_dir.mkdir()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        entry = data[i]\n",
    "        \n",
    "        for j in range(1,len(entry)):\n",
    "            if (entry[j] is None) == False:\n",
    "                parent_dir_name = 'no_moire' if j == 1 else 'moire'\n",
    "                parent_dir = set_dir / parent_dir_name\n",
    "    \n",
    "                if parent_dir.exists() == False:\n",
    "                    parent_dir.mkdir()\n",
    "                \n",
    "                out_path = parent_dir / f\"{ entry[0] }.{str(i).zfill(4)}.jpg\"\n",
    "            \n",
    "                img = Image.fromarray( np.uint8(data[i][j] * 255) ).convert('RGB')\n",
    "                img.save( out_path, progressive=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365426c-3b8a-4f13-8abd-f1ad8473ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tiles( sample, set_name ):\n",
    "    for i in tqdm(range(sample.shape[0])):\n",
    "        try:\n",
    "            write_tiles( process_sample( sample.iloc[i], dotenv ), set_name )\n",
    "        except:\n",
    "            print( sample.iloc[i].mask_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be482074-26c2-4a99-ae00-2f42dcafc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_moires():\n",
    "    # results laden\n",
    "    dotenv = load_dotenv()\n",
    "    moire_results = [r for r in get_results_of_project(2) if 'checked_moire' in r['labels']]\n",
    "    \n",
    "    results_frame = pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r['img_name'],\n",
    "                \";\".join([\n",
    "                    str(r['value']['x']),\n",
    "                    str(r['value']['y']),\n",
    "                    str(r['value']['width']),\n",
    "                    str(r['value']['height'])\n",
    "                ]),\n",
    "                r['rectanglelabels'][0]\n",
    "            )\n",
    "            for r in moire_results\n",
    "        ],\n",
    "        columns=['img_name','bbox','label']\n",
    "    )\n",
    "    \n",
    "    # masken laden\n",
    "    con = sqlite3.connect( dotenv['DB_PATH'] )\n",
    "    \n",
    "    masks = pd.read_sql(\n",
    "        'SELECT * FROM mask',\n",
    "        con\n",
    "    )\n",
    "    \n",
    "    masks.loc[\n",
    "        :,\n",
    "        'img_name'\n",
    "    ] = masks.apply(lambda val: f\"{ val.job }.{ val.pdf_filename }.{ val.method }.{ val.idx }.4c_600.jpg\", axis=1)\n",
    "\n",
    "    # Frames mergen\n",
    "    merged = pd.merge(\n",
    "        masks,\n",
    "        results_frame,\n",
    "        how=\"left\",\n",
    "        on=['img_name','bbox']\n",
    "    )\n",
    "    \n",
    "    merged = merged.loc[\n",
    "        merged.label == 'checked_moire'\n",
    "    ]\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb873f2-8f06-47d6-b29a-5a08131588ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c29e55-8896-4d25-884a-c4785efbfef7",
   "metadata": {},
   "source": [
    "# tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869a380-7ac2-4489-8a6c-5f74b6ab3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df04c6-1049-40eb-af68-629455006b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033fcfb-cff8-4a57-8577-23848efd02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = .2\n",
    "VAL_SIZE = .1\n",
    "TRAIN_SIZE = 1 - TEST_SIZE - VAL_SIZE\n",
    "\n",
    "N = 1000\n",
    "N = N if data.shape[0] > N else data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44924b54-0b30-4b23-a898-81fa93c07c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = list(set([\n",
    "    (e.parent.parent.name, e.parent.name, re.match(r'(.+)_\\d{3}.\\d+', e.name.replace(e.suffix,'')).groups()[0])\n",
    "    for e in DATASET_DIR.glob('./**/*.jpg')\n",
    "    if \"ok_sample\" not in e.name\n",
    "]))\n",
    "\n",
    "current_train = len([e for e in entries if e[0]=='train'])\n",
    "current_test = len([e for e in entries if e[0]=='test'])\n",
    "current_val = len([e for e in entries if e[0]=='val'])\n",
    "\n",
    "train_rows = []\n",
    "test_rows = []\n",
    "val_rows = []\n",
    "\n",
    "for i in range(N):\n",
    "    total = current_train + current_test + current_val + len(train_rows) + len(test_rows) + len(val_rows)\n",
    "    appended = False\n",
    "    possible_datasets = []\n",
    "\n",
    "    if (current_test + len(test_rows)) / total - TEST_SIZE < 0:\n",
    "        possible_datasets.append('test')\n",
    "\n",
    "    if (current_val + len(val_rows)) / total - VAL_SIZE < 0:\n",
    "        possible_datasets.append('val')\n",
    "\n",
    "    if (current_train + len(train_rows)) / total - TRAIN_SIZE < 0:\n",
    "        possible_datasets.append('train')\n",
    "\n",
    "    if len(possible_datasets) == 0:\n",
    "        possible_datasets = ['train','test','val']\n",
    "\n",
    "    next_dataset = random.choice(possible_datasets)\n",
    "\n",
    "    if next_dataset == 'train':\n",
    "        train_rows.append( data.iloc[i].name )\n",
    "    elif next_dataset == 'test':\n",
    "        test_rows.append( data.iloc[i].name )\n",
    "    elif next_dataset == 'val':\n",
    "        val_rows.append( data.iloc[i].name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d1460-a246-4d81-aac5-86bacaa15dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = data.loc[data.index.isin(test_rows)]\n",
    "val_rows = data.loc[data.index.isin(val_rows)]\n",
    "train_rows = data.loc[data.index.isin(train_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe05c3-afb8-4378-9b0b-6fb6ec564bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_rows), len(test_rows), len(val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c6dad-8a34-4a81-9fea-61d922ecdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tiles( train_rows, 'train' )\n",
    "generate_tiles( test_rows, 'test' )\n",
    "generate_tiles( val_rows, 'val' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ced27-d089-49fc-baee-45d045b11219",
   "metadata": {},
   "source": [
    "# ok_samples hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e4d0d-2e6b-417b-8ff8-dade82551f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_tiles = len(list(dotenv['TILE_DATASET_DIR'].glob('./**/ok_sample_*.jpg')))\n",
    "all_tiles = len(list(dotenv['TILE_DATASET_DIR'].glob('./**/*.jpg'))) - ok_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a413e-e0a6-4841-a6a7-332a6f1b25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_target_count = round(all_tiles * 0.5 - ok_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b1e6f-6d59-41f0-83bc-edee2a3e358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect( dotenv['DB_PATH'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab25f13-07f6-48b1-b4b9-9e335a02ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap( box, row, results_dict ):\n",
    "    relevant_boxes = []\n",
    "\n",
    "    if row.job not in results_dict:\n",
    "        return 0\n",
    "\n",
    "    if row.pdf_filename not in results_dict[row.job]:\n",
    "        return 0\n",
    "\n",
    "    intersections = []\n",
    "    for r in results_dict[row.job][row.pdf_filename]:    \n",
    "        intersection_box = [\n",
    "            max([box[0], r['x']]),\n",
    "            max([box[1], r['y']]),\n",
    "            min([box[0] + box[2], r['x'] + r['width']]),\n",
    "            min([box[1] + box[3], r['y'] + r['height']])\n",
    "        ]\n",
    "        \n",
    "        if intersection_box[0] <= intersection_box[2] and intersection_box[1] <= intersection_box[3]:\n",
    "            intersections.append((intersection_box[2] - intersection_box[0]) * (intersection_box[3] - intersection_box[1]))        \n",
    "\n",
    "    if len(intersections):\n",
    "        return max(intersections + [0])\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596567c-7ca4-46f1-8c3a-d0125cfa0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die im System vorhandenen Moires werden in eine Form gebracht, durch sie ausgeschlossen werden können\n",
    "real_moires = get_results_of_project(1)\n",
    "for r in real_moires:\n",
    "    r['dataset'] = 'real'\n",
    "\n",
    "generic_moires = get_results_of_project(2)\n",
    "for r in generic_moires:\n",
    "    r['dataset'] = 'generic'\n",
    "\n",
    "results = [\n",
    "    r for r in real_moires + generic_moires\n",
    "    if r['labels'][0] in ['checked_moire','moire_l_01','moire_l_05','moire_l_10','moire']\n",
    "]\n",
    "\n",
    "# die Boxen werden nach Job und pdf_filename\n",
    "# in ein dict einsortiert\n",
    "results_dict = {}\n",
    "\n",
    "for r in results:\n",
    "    if r['dataset'] == 'real':\n",
    "        job, pdf_filename, dpi = re.match(r'(.+?)\\..+?\\.(.+)\\.4c_(\\d+)\\.jpg', r['img_name']).groups()\n",
    "    else:\n",
    "        job, pdf_filename, dpi = re.match(r'(.+?)\\.(.+)\\.soft_light.+\\.4c_(\\d+)\\.jpg', r['img_name']).groups()\n",
    " \n",
    "    dpi = int(dpi)\n",
    "\n",
    "    out = {\n",
    "        'x' : r['value']['x'],\n",
    "        'y' : r['value']['y'],\n",
    "        'width' : r['value']['width'],\n",
    "        'height' : r['value']['height'],\n",
    "        'img_name' : r['img_name']\n",
    "    }\n",
    "\n",
    "    # boxen werden auf 600dpi skaliert\n",
    "    if dpi != dotenv['LOFI_DPI']:\n",
    "        rescale_factor = dotenv['LOFI_DPI'] / dpi\n",
    "\n",
    "        out['x'] = out['x'] * rescale_factor\n",
    "        out['y'] = out['y'] * rescale_factor\n",
    "        out['width'] = out['width'] * rescale_factor\n",
    "        out['height'] = out['height'] * rescale_factor\n",
    "\n",
    "    # result wird einsortiert\n",
    "    if job not in results_dict:\n",
    "        results_dict[job] = {}\n",
    "\n",
    "    if pdf_filename not in results_dict[job]:\n",
    "        results_dict[job][pdf_filename] = []\n",
    "\n",
    "    results_dict[job][pdf_filename].append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979c6c0-4ce8-46b1-83a4-7e1737ee6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_files = pd.read_sql(\n",
    "    '''\n",
    "        SELECT job, pdf_filename, filename FROM related_file rf\n",
    "        WHERE rf.variant_name == 'ps2400dpi150lpi' AND\n",
    "        \"type\" = '4c_600' AND job = '24-03-05-01_randomTrainPages'\n",
    "    ''',\n",
    "    con\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc57a72-5252-4f9d-9b78-8b460d5af95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ok_samples( found_tiles ):\n",
    "    random.shuffle(found_tiles)\n",
    "    \n",
    "    test_limiter = round(len(found_tiles) * TEST_SIZE)\n",
    "    val_limiter = test_limiter + round(len(found_tiles) * VAL_SIZE)\n",
    "    \n",
    "    test_rows = found_tiles[:test_limiter]\n",
    "    val_rows = found_tiles[test_limiter:val_limiter]\n",
    "    train_rows = found_tiles[val_limiter:]\n",
    "    \n",
    "    write_tiles( [(f\"ok_sample_{t[0]}_{t[1]}_\", t[3], None) for t in train_rows], 'train' )\n",
    "    write_tiles( [(f\"ok_sample_{t[0]}_{t[1]}_\", t[3], None) for t in test_rows], 'test' )\n",
    "    write_tiles( [(f\"ok_sample_{t[0]}_{t[1]}_\", t[3], None) for t in val_rows], 'val' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bba3f-a62c-4be4-a9d8-a9214e4618e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_out = 0\n",
    "found_tiles = []\n",
    "\n",
    "with tqdm(total=tile_target_count) as pbar: \n",
    "    while tiles_out < tile_target_count:\n",
    "        sample = related_files.sample(n=1).iloc[0]\n",
    "        filepath = get_related_filepath( sample.job, 'ps2400dpi150lpi', sample.filename )\n",
    "        orig_img = open_img(filepath)\n",
    "        source_dpi = dotenv[\"LOFI_DPI\"]\n",
    "        tiles_of_img = []\n",
    "        \n",
    "        i = 0\n",
    "        while random.random() > (len(tiles_of_img) / 30) ** 2 and i < 1000:\n",
    "            target_dpi = random.choice(RESOLUTIONS)\n",
    "            img = orig_img.resize((\n",
    "                round(orig_img.size[0] * (target_dpi / source_dpi)),\n",
    "                round(orig_img.size[1] * (target_dpi / source_dpi))\n",
    "            ))\n",
    "            \n",
    "            posX = random.randrange(img.size[0] - IMG_SIZE[0])\n",
    "            posY = random.randrange(img.size[1] - IMG_SIZE[1])\n",
    "        \n",
    "            tile_img = 1 - np.array(img.crop((\n",
    "                posX,posY,\n",
    "                posX+IMG_SIZE[0],posY+IMG_SIZE[1]\n",
    "            )))[:,:,3] / 255\n",
    "        \n",
    "            tiles_of_img.append((\n",
    "                sample.pdf_filename,\n",
    "                target_dpi,\n",
    "                (posX,posY),\n",
    "                tile_img\n",
    "            ))\n",
    "        \n",
    "            i += 1\n",
    "\n",
    "        found_tiles += tiles_of_img\n",
    "\n",
    "        if len(found_tiles) >= 100:\n",
    "            pbar.update(len(found_tiles))\n",
    "            tiles_out += len(found_tiles)\n",
    "            write_ok_samples(found_tiles)\n",
    "            found_tiles = []\n",
    "\n",
    "    pbar.update(len(found_tiles))\n",
    "    write_ok_samples( found_tiles )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef77d2-947c-4168-b27a-fcc9c9f53c73",
   "metadata": {},
   "source": [
    "# Real Validation schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102b627-b7b9-4c2a-a131-44ca9c252c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IOU = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63ac5d-d9d9-46d8-b7c8-05f8d946476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(dotenv['DB_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82be43c-7b73-4a9d-8e1c-a499045ae347",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979e8a5-4996-4f67-8403-1d021cdd2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "moires = [\n",
    "    r for r in get_results_of_project(3)\n",
    "    if 'moire' in r['labels'] and 'id' in r\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccb252-27e6-433d-a682-449fdcb5627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_real_moire( moire, dotenv, con ):\n",
    "    job, variant_name, pdf_filename, dpi = re.match(r'(.+?)\\.(.+?)\\.(.+)\\.4c_(\\d+).jpg', moire['img_name']).groups()\n",
    "    target_dpi = dotenv['TRAIN_DATA_DPI']\n",
    "\n",
    "    ps_path = get_related_filepath( job, 'ps2400dpi150lpi', f'{ pdf_filename }.4c_{ dotenv[\"LOFI_DPI\"] }.jpg' )\n",
    "\n",
    "    if ps_path is None:\n",
    "        return []\n",
    "\n",
    "    dpi = dotenv[\"LOFI_DPI\"]\n",
    "    ps_orig_img = open_img(ps_path)\n",
    "\n",
    "    # Größe der Punkte normalisieren\n",
    "    scale_factor_x = ps_orig_img.size[0] / moire['original_width']\n",
    "    scale_factor_y = ps_orig_img.size[1] / moire['original_height']\n",
    "    points_orig = [\n",
    "        (pt[0] * scale_factor_x, pt[1] * scale_factor_y)\n",
    "        for pt in moire['points']\n",
    "    ]\n",
    "    tiles = []\n",
    "\n",
    "    for resolution in RESOLUTIONS:\n",
    "        rescale_factor = resolution / dpi\n",
    "        ps_img = ps_orig_img.resize((\n",
    "            round(ps_orig_img.size[0] * rescale_factor),\n",
    "            round(ps_orig_img.size[1] * rescale_factor)\n",
    "        ))\n",
    "        points = [(pt[0] * rescale_factor, pt[1] * rescale_factor) for pt in points_orig]\n",
    "        \n",
    "        tiles += [\n",
    "            (f\"{moire['id']}_{ resolution }\", None, t)\n",
    "            for t in cut_img_to_tiles(\n",
    "                1 - np.array(ps_img)[:,:,3] / 255,\n",
    "                points,\n",
    "                is_polygon_box=True\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e367665-c31f-4309-a9a5-d68b1406e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_non_moire_tiles( moire, moires, dotenv, con ):\n",
    "    job, variant_name, pdf_filename, dpi = re.match(r'(.+?)\\.(.+?)\\.(.+)\\.4c_(\\d+).jpg', moire['img_name']).groups()\n",
    "    target_dpi = dotenv['TRAIN_DATA_DPI']\n",
    "    \n",
    "    ps_path = get_related_filepath( job, 'ps2400dpi150lpi', f'{ pdf_filename }.4c_{ dotenv[\"LOFI_DPI\"] }.jpg' )\n",
    "\n",
    "    if ps_path is None:\n",
    "        return []\n",
    "\n",
    "    dpi = dotenv[\"LOFI_DPI\"]\n",
    "    ps_orig_img = open_img(ps_path)\n",
    "\n",
    "    # Größe der Punkte normalisieren\n",
    "    scale_factor_x = ps_orig_img.size[0] / moire['original_width']\n",
    "    scale_factor_y = ps_orig_img.size[1] / moire['original_height']\n",
    "    relevant_boxes_orig = [\n",
    "        [(pt[0] * scale_factor_x, pt[1] * scale_factor_y) for pt in m['points']]\n",
    "        for m in moires\n",
    "        if m['img_name'] == moire['img_name']\n",
    "    ]\n",
    "    tiles = []\n",
    "\n",
    "    resources_by_resolution = {}\n",
    "    \n",
    "    for resolution in RESOLUTIONS:\n",
    "        rescale_factor = resolution / dpi\n",
    "        ps_img = ps_orig_img.resize((\n",
    "            round(ps_orig_img.size[0] * rescale_factor),\n",
    "            round(ps_orig_img.size[1] * rescale_factor)\n",
    "        ))\n",
    "        relevant_boxes = [[(pt[0] * rescale_factor, pt[1] * rescale_factor) for pt in ptm] for ptm in relevant_boxes_orig]\n",
    "    \n",
    "        resources_by_resolution[resolution] = {\n",
    "            'img' : ps_img,\n",
    "            'boxes' : relevant_boxes\n",
    "        }\n",
    "   \n",
    "    iterations = 0\n",
    "    tiles = []\n",
    "    while len(tiles) < 25 and iterations < 1000:\n",
    "        target_resolution = random.choice(list(resources_by_resolution.keys()))\n",
    "        target_img = resources_by_resolution[target_resolution]\n",
    "        \n",
    "        posX = random.randrange( target_img['img'].size[0] - IMG_SIZE[0] )\n",
    "        posY = random.randrange( target_img['img'].size[1] - IMG_SIZE[1] )\n",
    "\n",
    "        for rb in target_img['boxes']:\n",
    "            p_label = Polygon(rb)\n",
    "            p_tile = Polygon([\n",
    "                (posX,posY),\n",
    "                (posX + IMG_SIZE[0],posY),\n",
    "                (posX + IMG_SIZE[0],posY + IMG_SIZE[1]),\n",
    "                (posX,posY + IMG_SIZE[1])\n",
    "            ])          \n",
    "\n",
    "            if p_label.intersection(p_tile).area == 0:\n",
    "                tiles.append((\n",
    "                    target_resolution,\n",
    "                    1 - np.array(ps_img.crop((\n",
    "                        posX,\n",
    "                        posY,\n",
    "                        posX + IMG_SIZE[0],\n",
    "                        posY + IMG_SIZE[1]\n",
    "                    )))[:,:,3] / 255\n",
    "                ))\n",
    "        \n",
    "        iterations += 1\n",
    "    \n",
    "    return [(f\"{ moire['id'] }_ok_sample_{ t[0] }\", t[1], None ) for t in tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b67f29-e08d-4647-a829-3145ce93f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in tqdm(moires):\n",
    "    if len(list((dotenv['TILE_DATASET_DIR'] / 'real_val' / 'moire').glob(f'./{ m[\"id\"] }*.jpg'))) == 0:\n",
    "        moire_tiles = process_real_moire(m, dotenv, con)\n",
    "        write_tiles( moire_tiles, 'real_val' )\n",
    "    \n",
    "        no_moire_tiles = get_real_non_moire_tiles( m, moires, dotenv, con )\n",
    "        write_tiles( no_moire_tiles, 'real_val' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b15513-05ed-4126-b46b-105102aab6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "moire_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043e65c-e37b-4e50-86f7-cc7d721ee0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(real_moire_tiles), len(real_non_moire_tiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
