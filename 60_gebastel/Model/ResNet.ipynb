{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0acf9d-ae81-4b04-aa4e-f7abef31927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../30_data_tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3591e6dc-0ce3-4056-83fb-6e4b3a34ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up CUDA in OS\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# Import libabries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78e3fc6-37fc-40e8-94ee-9a17a5c560e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from helper import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dddb170-c3cd-4604-895e-c40926a92ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1265149e-a668-4d76-ba90-4079c57fabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27b92fd-e25d-4950-90db-a6a22041a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd9b930-0bcf-4691-a08b-008fdee2246d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out if a GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92eb01b-63e5-4262-af81-25c3fbecd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f6d752-8f32-45d6-96e5-fecf5b779df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = {}\n",
    "for entry in DATASET_DIR.iterdir():\n",
    "    if entry.is_dir() and entry.name.startswith('.') == False:\n",
    "        available_datasets[entry.name] = {\n",
    "            'path' : entry\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ed4609-9561-4b5c-b7dc-ae863fe977b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform function\n",
    "transforms_data = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3587beec-1a6f-4fb8-8249-f1dd0a4eefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in available_datasets:\n",
    "    available_datasets[key]['dataset'] = datasets.ImageFolder(available_datasets[key]['path'], transforms_data)\n",
    "    available_datasets[key]['dataloader'] = torch.utils.data.DataLoader(available_datasets[key]['dataset'], batch_size=12, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "753d9a58-39ea-4127-886f-d416d9023552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_val size 3916\n",
      "test size 1276\n",
      "train size 5051\n",
      "val size 574\n",
      "class names ['moire', 'no_moire']\n"
     ]
    }
   ],
   "source": [
    "for key in available_datasets:\n",
    "    print(f'{ key } size', len(available_datasets[key]['dataset']))\n",
    "\n",
    "print('class names', available_datasets[list(available_datasets.keys())[0]]['dataset'].classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b631063-1829-4568-bc47-c5c236286a7d",
   "metadata": {},
   "source": [
    "# get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b9f824-d098-46dc-951d-496c618df606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50683e6b-275e-4c62-8a97-341fba6d7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features from pre-trained model 512\n"
     ]
    }
   ],
   "source": [
    "num_features = model.fc.in_features \n",
    "print('Number of features from pre-trained model', num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb305bfe-eb2e-480f-ac2b-b33e4fa7ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673f1fb1-9210-4153-88ee-356c218d5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fully-connected layer for classification\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234a572-554f-4836-a0a3-6fbf95e44ebc",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f7a26bf-cb65-4568-8181-dbd3cc915142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c558cd45-a0a0-489c-9637-00314fae7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d34812de-bbd0-4b83-bcc0-289cb4d37b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c01d35b9-07a9-44f4-88db-16569e50f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #1] Loss: 0.0390 Acc: 84.4981% Time: 163.2149s\n",
      "[Test #1] Loss: 0.0376 Acc: 87.3824% Time: 179.2125s\n",
      "Epoch 1 running\n",
      "[Train #2] Loss: 0.0383 Acc: 85.2702% Time: 337.4601s\n",
      "[Test #2] Loss: 0.0391 Acc: 85.3448% Time: 353.3042s\n",
      "Epoch 2 running\n",
      "[Train #3] Loss: 0.0377 Acc: 86.4977% Time: 509.7642s\n",
      "[Test #3] Loss: 0.0370 Acc: 88.5580% Time: 525.5239s\n",
      "Epoch 3 running\n",
      "[Train #4] Loss: 0.0370 Acc: 87.1907% Time: 679.7142s\n",
      "[Test #4] Loss: 0.0371 Acc: 88.0094% Time: 695.6976s\n",
      "Epoch 4 running\n",
      "[Train #5] Loss: 0.0366 Acc: 87.8638% Time: 851.3272s\n",
      "[Test #5] Loss: 0.0369 Acc: 87.9310% Time: 867.1253s\n",
      "Epoch 5 running\n",
      "[Train #6] Loss: 0.0362 Acc: 88.5765% Time: 1022.0216s\n",
      "[Test #6] Loss: 0.0383 Acc: 85.5016% Time: 1037.7133s\n",
      "Epoch 6 running\n",
      "[Train #7] Loss: 0.0360 Acc: 88.4379% Time: 1193.1716s\n",
      "[Test #7] Loss: 0.0370 Acc: 87.8527% Time: 1208.9509s\n",
      "Epoch 7 running\n",
      "[Train #8] Loss: 0.0361 Acc: 88.2004% Time: 1365.9435s\n",
      "[Test #8] Loss: 0.0369 Acc: 87.4608% Time: 1381.7345s\n",
      "Epoch 8 running\n",
      "[Train #9] Loss: 0.0354 Acc: 89.5070% Time: 1539.5445s\n",
      "[Test #9] Loss: 0.0369 Acc: 88.6364% Time: 1555.5787s\n",
      "Epoch 9 running\n",
      "[Train #10] Loss: 0.0354 Acc: 89.1111% Time: 1713.2522s\n",
      "[Test #10] Loss: 0.0358 Acc: 89.3417% Time: 1729.2519s\n"
     ]
    }
   ],
   "source": [
    "#### Train model\n",
    "train_loss=[]\n",
    "train_accuary=[]\n",
    "test_loss=[]\n",
    "test_accuary=[]\n",
    "\n",
    "num_epochs = 10   #(set no of epochs)\n",
    "start_time = time.time() #(for showing time)\n",
    "# Start loop\n",
    "for epoch in range(num_epochs): #(loop for every epoch)\n",
    "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    #(training model)\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0 \n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(available_datasets['train']['dataloader']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device) \n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "    epoch_loss = running_loss / len(available_datasets['train']['dataset'])\n",
    "    epoch_acc = running_corrects / len(available_datasets['train']['dataset']) * 100.\n",
    "    # Append result\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuary.append(epoch_acc)\n",
    "    # Print progress\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    \"\"\" Testing Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in available_datasets['test']['dataloader']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "        epoch_loss = running_loss / len(available_datasets['test']['dataset'])\n",
    "        epoch_acc = running_corrects / len(available_datasets['test']['dataset']) * 100.\n",
    "        # Append result\n",
    "        test_loss.append(epoch_loss)\n",
    "        test_accuary.append(epoch_acc)\n",
    "        # Print progress\n",
    "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37813712-4674-4af6-9bd7-56eebf5a2cc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7914e250-45f8-4e46-a0be-d39f2a14ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dotenv['MODEL_DIR'] / '24-02-24_02_resNet.pt'\n",
    "\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2128c6-8de3-4fde-b808-463729c503a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6055606-5767-4de3-83e9-fe2dff8ad3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_labels = []\n",
    "val_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in available_datasets['val']['dataloader']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        val_labels += labels.tolist()\n",
    "        val_predictions += preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e5378-7a67-49c5-8483-726cfe5d32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(val_labels)):\n",
    "    # Positive == 1, Negative == 0\n",
    "    if val_labels[i] == 1 and val_predictions[i] == 1:\n",
    "        TP += 1\n",
    "    elif val_labels[i] == 0 and val_predictions[i] == 0:\n",
    "        TN += 1\n",
    "    elif val_labels[i] == 0 and val_predictions[i] == 1:\n",
    "        FP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "correct_classified = TP + TN\n",
    "accuracy = correct_classified / len(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394e748-87ef-4fe8-b455-44e23de7dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209a42b-b1d9-412b-a11d-12aaa86da39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a1eab-149e-4023-9d8d-cec62bd3da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37827a23-5e18-45a4-9210-f87bc4aa22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfbda8-85f0-47ec-85b9-ef9c4978d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    x=np.arange(1,num_epochs+1),\n",
    "    y=train_accuary\n",
    ")\n",
    "\n",
    "# Only thing I figured is - I could do this \n",
    "fig.add_scatter(\n",
    "    x=np.arange(1,num_epochs+1),\n",
    "    y=test_accuary\n",
    ") # Not what is desired - need a line \n",
    "\n",
    "# Show plot \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
