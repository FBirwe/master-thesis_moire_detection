{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ebdf6e-3c55-4785-b5de-76db2e4005ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2c3f4b-d34b-47d2-ac94-f56c27f9611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e536e64c-542b-4930-8a98-9c4c0fb3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08b4243-c60a-4e37-a754-60b8e15d8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9d31e3-ef8d-4d74-98fc-bd62ffd1d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_frequencies( fft, inner_limit=0, outer_limit=140 ):\n",
    "    center = (fft.shape[1] / 2, fft.shape[0] / 2)\n",
    "    for y in range(fft.shape[0]):\n",
    "        for x in range(fft.shape[1]):\n",
    "            r = math.sqrt( abs(center[0] - x) ** 2 + abs(center[1] - y) ** 2 )\n",
    "            if r > outer_limit:\n",
    "                fft[y,x] = 0\n",
    "    \n",
    "            if r < inner_limit:\n",
    "                fft[y,x] = 0\n",
    "\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae66add-2164-471f-b30b-70c20a08de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2dft( input_img ):\n",
    "    input = np.float32( input_img )[:,:,0]\n",
    "    dft = np.fft.fft2(input)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    ft = np.real(dft_shift)\n",
    "    ft = limit_frequencies( ft, inner_limit=25, outer_limit=120)\n",
    "    ft[int(ft.shape[0] / 2),int(ft.shape[1] / 2)] = 0\n",
    "    \n",
    "    return torch.Tensor(ft).reshape((1,ft.shape[0],ft.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f70da8-9f20-45d8-9dbf-3d096326a417",
   "metadata": {},
   "source": [
    "# Datenset laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4280085-bd39-4250-8d7c-623e30af6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./dataset/train/\"\n",
    "test_dir = \"./dataset/test/\"\n",
    "train_classa_dir = \"./dataset/train/moire/\"\n",
    "train_classb_dir = \"./dataset/train/no_moire/\"\n",
    "test_classa_dir = \"./dataset/test/moire/\"\n",
    "test_classb_dir = \"./dataset/test/no_moire/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b77058a-37e2-48b7-bb94-bf8318762a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform function\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Lambda(calculate_2dft)\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Lambda(calculate_2dft)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2880b7c-7f41-4d20-8902-a56dc1a7b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=48, shuffle=True, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=48, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084207fb-7e35-404b-8e59-e040983bb6db",
   "metadata": {},
   "source": [
    "# Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "258f6765-f795-4046-abb9-3ca49b09e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('mps')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17df6295-c24f-4321-96f8-070514dba3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(12, 35, 5, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(35840, 20000)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(20000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39476305-0971-4ade-9dad-2f6856156f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f2ab078-734f-4ac4-a3e8-744a4fc36024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca761b5-6a67-48af-8187-97c688d43125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7418ed14-23a4-49ea-acb6-dd079bdba76b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "0 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a187caa-d994-4ec5-bfb0-d6a61af9463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [10:28<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #1] Loss: 0.0146 Acc: 48.7032% Time: 628.3222s\n",
      "[Test #1] Loss: 0.0147 Acc: 49.1379% Time: 672.9256s\n",
      "Epoch 2 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [11:59<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #2] Loss: 0.0145 Acc: 48.3073% Time: 1392.5499s\n",
      "[Test #2] Loss: 0.0147 Acc: 49.0596% Time: 1430.5423s\n",
      "Epoch 3 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [11:17<00:00,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #3] Loss: 0.0145 Acc: 48.3469% Time: 2108.3147s\n",
      "[Test #3] Loss: 0.0147 Acc: 49.0596% Time: 2145.2372s\n",
      "Epoch 4 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [11:22<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #4] Loss: 0.0145 Acc: 48.3469% Time: 2827.8900s\n",
      "[Test #4] Loss: 0.0147 Acc: 49.0596% Time: 2865.1107s\n",
      "Epoch 5 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [10:56<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #5] Loss: 0.0145 Acc: 48.3469% Time: 3521.4522s\n",
      "[Test #5] Loss: 0.0147 Acc: 49.0596% Time: 3558.8857s\n",
      "Epoch 6 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [39:04<00:00, 22.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #6] Loss: 0.0145 Acc: 48.3073% Time: 5903.1194s\n",
      "[Test #6] Loss: 0.0147 Acc: 49.0596% Time: 6169.1563s\n",
      "Epoch 7 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [40:06<00:00, 22.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #7] Loss: 0.0145 Acc: 48.3667% Time: 8575.9163s\n",
      "[Test #7] Loss: 0.0147 Acc: 49.1379% Time: 8613.4055s\n",
      "Epoch 8 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [11:27<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #8] Loss: 0.0145 Acc: 48.3667% Time: 9300.4285s\n",
      "[Test #8] Loss: 0.0147 Acc: 49.1379% Time: 9337.9717s\n",
      "Epoch 9 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [11:21<00:00,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #9] Loss: 0.0145 Acc: 48.3865% Time: 10019.5405s\n",
      "[Test #9] Loss: 0.0147 Acc: 49.2163% Time: 10057.1064s\n",
      "Epoch 10 running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 106/106 [12:03<00:00,  6.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train #10] Loss: 0.0145 Acc: 48.4063% Time: 10780.4517s\n",
      "[Test #10] Loss: 0.0147 Acc: 49.2163% Time: 10818.0385s\n"
     ]
    }
   ],
   "source": [
    "#### Train model\n",
    "train_loss=[]\n",
    "train_accuary=[]\n",
    "test_loss=[]\n",
    "test_accuary=[]\n",
    "\n",
    "num_epochs = 10   #(set no of epochs)\n",
    "start_time = time.time() #(for showing time)\n",
    "# Start loop\n",
    "for epoch in range(num_epochs): #(loop for every epoch)\n",
    "    print(\"Epoch {} running\".format(epoch + 1)) #(printing message)\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    #(training model)\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0 \n",
    "    # load a batch data of images\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:       \n",
    "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            # forward inputs and get output\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # get loss value and update the network weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    # Append result\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuary.append(epoch_acc)\n",
    "    # Print progress\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    \"\"\" Testing Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "        epoch_loss = running_loss / len(test_dataset)\n",
    "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
    "        # Append result\n",
    "        test_loss.append(epoch_loss)\n",
    "        test_accuary.append(epoch_acc)\n",
    "        # Print progress\n",
    "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch+1, epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
