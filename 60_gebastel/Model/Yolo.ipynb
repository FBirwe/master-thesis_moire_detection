{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46b1843-3950-43f9-a377-07aca2382399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import YOLO model\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b062c61-64e7-4ca4-b4cf-03a362698a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size 640x640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9786a17-44aa-4c9b-a8b0-a82cb3555f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-cls.pt to 'yolov8m-cls.pt'...\n",
      "‚ö†Ô∏è Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-cls.pt...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO('yolov8m-cls.pt') # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856962a3-a005-4521-94bf-e5d9ad1b79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = YOLO(dotenv['MODEL_DIR'] / 'yolov8_moires_24-02-22.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f115f5-203c-4ba2-bb30-009bfec44189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.18 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.184 üöÄ Python-3.10.11 torch-2.0.1 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=./dataset/, epochs=10, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/train... found 5051 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/val... found 574 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/test... found 1276 images in 2 classes ‚úÖ \n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15774898 parameters, 15774898 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_det\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detec\u001b[0m\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       1/10         0G     0.1087         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:33<00\n",
      "                   all       0.84          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       2/10         0G    0.07032         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:33<00\n",
      "                   all      0.822          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       3/10         0G    0.06311         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:34<00\n",
      "                   all      0.821          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       4/10         0G    0.05309         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:17<00\n",
      "                   all      0.852          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       5/10         0G    0.03747         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:18<00\n",
      "                   all      0.826          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       6/10         0G    0.03608         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:18<00\n",
      "                   all      0.845          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       7/10         0G    0.02087         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:18<00\n",
      "                   all      0.876          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       8/10         0G    0.01565         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:19<00\n",
      "                   all      0.871          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "       9/10         0G    0.01007         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:18<00\n",
      "                   all      0.883          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      10/10         0G   0.006838         11        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 316/\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [02:40<00\n",
      "                   all      0.885          1\n",
      "\n",
      "10 epochs completed in 2.737 hours.\n",
      "Optimizer stripped from /Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from /Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating /Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.184 üöÄ Python-3.10.11 torch-2.0.1 CPU (Apple M1 Pro)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15765218 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/train... found 5051 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/val... found 574 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/test... found 1276 images in 2 classes ‚úÖ \n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [02:46<00\n",
      "                   all      0.885          1\n",
      "Speed: 0.0ms preprocess, 285.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22\u001b[0m\n",
      "Results saved to \u001b[1m/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x29d9d4340>\n",
       "fitness: 0.9425086975097656\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8850173950195312, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9425086975097656}\n",
       "save_dir: PosixPath('/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/train22')\n",
       "speed: {'preprocess': 0.0008564792859014318, 'inference': 285.43388137418634, 'loss': 0.00014496181900077582, 'postprocess': 0.0001287626472499728}\n",
       "top1: 0.8850173950195312\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train(data='./dataset/', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c94e1a8-1cba-4f8b-b0b5-3c4f974cc5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.184 üöÄ Python-3.10.11 torch-2.0.1 CPU (Apple M1 Pro)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15765218 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/train... found 5051 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/val... found 574 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detection/60_gebastel/Model/dataset/test... found 1276 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/frederic.birwe/Documents/GitHub/master-thesis_moire_detec\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [06:04<00\n",
      "                   all      0.885          1\n",
      "Speed: 0.0ms preprocess, 627.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/val25\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.val() # no arguments needed, dataset and settings remembered\n",
    "metrics.top1 # top1 accuracy\n",
    "metrics.top5 # top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417311a4-bb9b-4e01-a093-f24913aa49be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/val25'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(metrics.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb49eb9-2e97-4bce-9fcc-79320b5beae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open '/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/val19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5637befa-4065-43c7-9d9b-f294f981a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        222,          15],\n",
       "       [         51,         286]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277855d3-5f19-4c57-a455-5c44c7aec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76747970-d5f6-4fda-a691-b418896e8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c643ef5a-8f4b-480c-b31c-9d9e891e820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../30_data_tools/')\n",
    "from helper import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd887c7-9b00-46a1-af44-04b0885025e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d598bd7d-7a1d-4aa5-b7d2-78699053ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(dotenv['MODEL_DIR'] / 'yolov8_moires_24-02-22.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a83432b9-e2a6-4e6e-99e3-603597dfbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moire_img = list( Path('./dataset/test/moire/').glob('./*.jpg') )\n",
    "non_moire_img = list( Path('./dataset/test/no_moire/').glob('./*.jpg') )\n",
    "\n",
    "data = moire_img + non_moire_img\n",
    "labels = [1 for i in moire_img] + [0 for i in non_moire_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bb8ba2c-d58c-44f8-92c7-c1d58ca559d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab3696550b94b8bae06ca6e3ac2a244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.val()\n",
    "predictions = []\n",
    "target_labels = []\n",
    "\n",
    "for entry in tqdm(data):\n",
    "    pred = model.predict(entry, verbose=False)[0].probs.data\n",
    "    predictions.append(pred)\n",
    "    target_labels.append( 1 - int(torch.argmax(pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035c37a1-fdd1-44d0-a952-5bde1c4a272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/frederic.birwe/Desktop/test/pagina-finder-webapp/runs/classify/val25'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(metrics.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5ca54ac-68d5-41fa-99f9-8a081f7ca2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    # Positive == 1, Negative == 0\n",
    "    res = labels[i] - target_labels[i]\n",
    "    if res == 0:\n",
    "        if labels[i] == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    elif res == -1:\n",
    "        FP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "correct_values = TP + TN\n",
    "accuracy = correct_values / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86ce264d-8d9f-4988-8be8-5b9719513556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 649, 17, 127)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79542618-02bc-40b4-a5ed-9bc3d51f4cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918032786885246"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "031f7181-078b-426f-a823-89205349adfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7918032786885246, 0.966)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "474c3d04-0443-47b3-bedd-cc789df9905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1132/1276, 0.8871473354231975'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{(TP + TN)}/{len(labels)}, {accuracy}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4614b158-0972-41d5-83a8-4be0951fac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715d89fd-6bdf-42ea-9221-096199444689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd882fc51794b45ac9e437f5739cbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1,len(labels))):\n",
    "    # Positive == 1, Negative == 0\n",
    "    res = labels[i] - target_labels[i]\n",
    "    if res == 1:\n",
    "        dir_path = Path('./temp/FN/')\n",
    "\n",
    "        if dir_path.exists() == False:\n",
    "            dir_path.mkdir()\n",
    "    elif res == -1:\n",
    "        dir_path = Path('./temp/FP/')\n",
    "\n",
    "        if dir_path.exists() == False:\n",
    "            dir_path.mkdir()\n",
    "\n",
    "    if res != 0:\n",
    "        out_path = dir_path / data[i].name\n",
    "        shutil.copy( data[i], out_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75f59c9c-8d28-4755-a5af-f7a790c99b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892b66a6-d678-4a67-a2b2-b92d7d9efa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2409, 0.7591])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data[i], verbose=False)[0].probs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c72d632c-332a-4963-843f-6f7c9a7d61be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "dataset/train/moire/508890.HBZP_1_M_270.p1.soft_light.1.4c_600.jpg.0908.jpg does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./dataset/train/moire/508890.HBZP_1_M_270.p1.soft_light.1.4c_600.jpg.0908.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/engine/model.py:236\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/engine/predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/engine/predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model(model)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_txt:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/engine/predictor.py:207\u001b[0m, in \u001b[0;36mBasePredictor.setup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsz \u001b[38;5;241m=\u001b[39m check_imgsz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstride, min_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m, classify_transforms(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsz[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_inference_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msource_type\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m  \u001b[38;5;66;03m# streams\u001b[39;00m\n\u001b[1;32m    213\u001b[0m                                           \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m  \u001b[38;5;66;03m# images\u001b[39;00m\n\u001b[1;32m    214\u001b[0m                                           \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_flag\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))):  \u001b[38;5;66;03m# videos\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/data/build.py:166\u001b[0m, in \u001b[0;36mload_inference_source\u001b[0;34m(source, imgsz, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    164\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m LoadPilAndNumpy(source, imgsz\u001b[38;5;241m=\u001b[39mimgsz)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLoadImages\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvid_stride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_type\u001b[39m\u001b[38;5;124m'\u001b[39m, source_type)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ultralytics/data/loaders.py:215\u001b[0m, in \u001b[0;36mLoadImages.__init__\u001b[0;34m(self, path, imgsz, vid_stride)\u001b[0m\n\u001b[1;32m    213\u001b[0m         files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m((parent \u001b[38;5;241m/\u001b[39m p)\u001b[38;5;241m.\u001b[39mabsolute()))  \u001b[38;5;66;03m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    217\u001b[0m images \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m IMG_FORMATS]\n\u001b[1;32m    218\u001b[0m videos \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m VID_FORMATS]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: dataset/train/moire/508890.HBZP_1_M_270.p1.soft_light.1.4c_600.jpg.0908.jpg does not exist"
     ]
    }
   ],
   "source": [
    "model.predict(Path('./dataset/train/moire/508890.HBZP_1_M_270.p1.soft_light.1.4c_600.jpg.0908.jpg'), verbose=False)[0].probs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11ebce-7b90-4868-886a-2a4eaa04b27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1b3be-26e9-41f2-8b57-e94bb67e145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    '1' : [],\n",
    "    '0.5' : [],\n",
    "    '-0.5' : [],\n",
    "    '-1' : []\n",
    "}\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    diff = float(predictions[i][0] - predictions[i][1])\n",
    "\n",
    "    if diff > 0.5:\n",
    "        classes['1'].append(i)\n",
    "    elif diff >= 0:\n",
    "        classes['0.5'].append(i)\n",
    "    elif diff >= -.5:\n",
    "        classes['-0.5'].append(i)\n",
    "    else:\n",
    "        classes['-1'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824f4cc-abb3-4180-8439-74813f9c9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    acc = len([True for i in classes[c] if labels[i] - target_labels[i] == 0]) / len(classes[c])\n",
    "\n",
    "    print(c, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28c948-bb4b-4415-aca7-e77e85617108",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = randrange(len(data))\n",
    "print(i, data[i].name)\n",
    "print(predictions[i], labels[i],target_labels[i])\n",
    "Image.open(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21337978-2d6a-4531-ba83-0f9abc659c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128df08-bc78-45b5-bdb8-837e0e1acc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(\n",
    "    [(float(predictions[i][0]),float(predictions[i][1]),labels[i],target_labels[i]) for i in range(len(labels))],\n",
    "    columns=['pred_moire','pred_no_moire','label','target_label']\n",
    ")\n",
    "\n",
    "res_df.loc[\n",
    "    :,\n",
    "    'pred_diff'\n",
    "] = res_df.pred_moire - res_df.pred_no_moire\n",
    "res_df.loc[\n",
    "    :,\n",
    "    'pred_correct'\n",
    "] = res_df.label == res_df.target_label\n",
    "res_df.loc[\n",
    "    :,\n",
    "    'pred_diff_abs'\n",
    "] = res_df.pred_diff.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f6f44-6aab-4ecd-8874-713c6ef5c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f743aa-4420-4801-9668-8d255d7191bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    y=res_df.pred_diff_abs,\n",
    "    color=res_df.pred_correct\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38014d1a-3f02-49ef-aefd-920a38153857",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    sorted([p[0]-p[1] for p in predictions], reverse=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe8aa1-147f-4db0-9731-16eac9b7ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    [p[0] for p in predictions]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702188f-6045-4004-902c-92936ab2bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    [p[1] for p in predictions]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
